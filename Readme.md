👨‍💻 About Me

Data science professional with 2+ years of experience in machine learning, statistical modelling, data manipulation, ETL processes, predictive modelling and effective storytelling. Proficient in standard data tools and packages like Python, R, SQL, Tableau and PowerBI.

🛠️ My journey in data science began with a strong background in computer engineering, evolving into a passion for extracting insights from complex datasets. I specialise in building scalable and efficient machine learning models and deploying them on cloud platforms such as AWS and Azure. My experience spans multiple industries, including real-estate, fashion and healthcare, where I have consistently delivered actionable insights and optimised data processes. I am eager to apply my skills to new industries, embracing fresh challenges and opportunities for growth.

🚀 My motto: "Data is the new oil; let's refine it."

💻 Programming Languages: Python, R, Java, C++, JavaScript, SQL

🔧 Technologies & Tools: TensorFlow, Scikit-learn, PyTorch, Keras, Langchain, Streamlit, Django, Angular, 
                RESTful APIs, FastAPI, PostgreSQL, MySQL, MongoDB, Apache Airflow, Apache Spark, Tableau, PowerBI, Docker, Kubernetes, Data Warehousing, 
                Shell scripting, Documentation

☁️ Cloud: CI/CD, Git, Bitbucket, Gitlab, AWS: Sagemaker, Fargate, CodePipeline, S3, EC2,  Lambda; GCP: AI Platform, Google Cloud Run, Google Cloud Build, Google Cloud Storage, Google Compute Engine, Google Cloud Functions; Azure: Azure Machine Learning, Azure Container Instances, Azure DevOps Pipelines, Azure Blob Storage, Azure Virtual Machines, Azure Functions

📊 Methodologies: SCRUM, Agile, TDD

🌐 Interests: Machine Learning, Deep Learning, NLP, LLM, RPA
